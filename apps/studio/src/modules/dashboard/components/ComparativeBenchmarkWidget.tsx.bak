import React, { useMemo, useState } from 'react';
import { Table, Segmented, Space, theme, Tooltip, Progress } from 'antd';
import {
  HolderOutlined,
  BarChartOutlined,
  TrophyOutlined,
  ThunderboltOutlined,
  ClockCircleOutlined,
  FireOutlined,
} from '@ant-design/icons';
import { KBBarChart } from '@kb-labs/studio-ui-react';
import { useDataSources } from '../../../providers/data-sources-provider';
import { usePrometheusMetrics, useAdaptersLLMUsage } from '@kb-labs/studio-data-client';
import { UICard, UIText } from '@kb-labs/studio-ui-kit';

const { useToken } = theme;

interface BenchmarkEntry {
  name: string;
  requests: number;
  errors: number;
  avgLatency: number;
  p95Latency: number;
  errorRate: number;
  throughput: number;
  score: number;
  rank: number;
  badge?: 'gold' | 'silver' | 'bronze';
}

type BenchmarkCategory = 'plugins' | 'adapters';
type SortBy = 'score' | 'requests' | 'latency' | 'errorRate';

export function ComparativeBenchmarkWidget() {
  const { token } = useToken();
  const sources = useDataSources();
  const metrics = usePrometheusMetrics(sources.observability);
  const llmUsage = useAdaptersLLMUsage(sources.adapters);

  const [category, setCategory] = useState<BenchmarkCategory>('plugins');
  const [sortBy, setSortBy] = useState<SortBy>('score');

  // Calculate benchmark scores for plugins
  const pluginBenchmarks = useMemo(() => {
    if (!metrics.data?.perPlugin) return [];

    const entries: BenchmarkEntry[] = metrics.data.perPlugin.map((plugin) => {
      const requests = plugin.requests ?? 0;
      const errors = plugin.errors ?? 0;
      const avgLatency = plugin.latency?.average ?? 0;
      const p95Latency = plugin.latency?.p95 ?? 0;
      const errorRate = requests > 0 ? (errors / requests) * 100 : 0;
      const throughput = requests; // requests per minute

      // Calculate composite score (0-100)
      const latencyScore = Math.max(0, 100 - avgLatency / 10); // 0ms=100, 1000ms=0
      const errorScore = Math.max(0, 100 - errorRate * 10); // 0%=100, 10%=0
      const throughputScore = Math.min(100, (throughput / 100) * 10); // 1000req=100
      const score = (latencyScore * 0.4 + errorScore * 0.4 + throughputScore * 0.2);

      return {
        name: plugin.pluginId,
        requests,
        errors,
        avgLatency,
        p95Latency,
        errorRate,
        throughput,
        score,
        rank: 0,
      };
    });

    // Sort by score and assign ranks
    entries.sort((a, b) => b.score - a.score);
    entries.forEach((entry, index) => {
      entry.rank = index + 1;
      if (index === 0) entry.badge = 'gold';
      else if (index === 1) entry.badge = 'silver';
      else if (index === 2) entry.badge = 'bronze';
    });

    return entries;
  }, [metrics.data]);

  // Calculate benchmark scores for adapters (LLM)
  const adapterBenchmarks = useMemo(() => {
    if (!llmUsage.data?.byModel) return [];

    const entries: BenchmarkEntry[] = Object.entries(llmUsage.data.byModel).map(([model, stats]) => {
      const requests = stats.requests ?? 0;
      const avgLatency = stats.avgDurationMs ?? 0;
      const throughput = requests;
      const errors = 0; // LLM usage doesn't track errors separately
      const errorRate = 0;

      // Calculate composite score for LLM models
      const latencyScore = Math.max(0, 100 - avgLatency / 50); // 0ms=100, 5000ms=0
      const throughputScore = Math.min(100, (throughput / 50) * 10); // 500req=100
      const score = (latencyScore * 0.6 + throughputScore * 0.4);

      return {
        name: model,
        requests,
        errors,
        avgLatency,
        p95Latency: avgLatency * 1.5, // Estimate p95
        errorRate,
        throughput,
        score,
        rank: 0,
      };
    });

    // Sort by score and assign ranks
    entries.sort((a, b) => b.score - a.score);
    entries.forEach((entry, index) => {
      entry.rank = index + 1;
      if (index === 0) entry.badge = 'gold';
      else if (index === 1) entry.badge = 'silver';
      else if (index === 2) entry.badge = 'bronze';
    });

    return entries;
  }, [llmUsage.data]);

  const data = category === 'plugins' ? pluginBenchmarks : adapterBenchmarks;

  // Sort data based on selected criterion
  const sortedData = useMemo(() => {
    const sorted = [...data];
    switch (sortBy) {
      case 'score':
        sorted.sort((a, b) => b.score - a.score);
        break;
      case 'requests':
        sorted.sort((a, b) => b.requests - a.requests);
        break;
      case 'latency':
        sorted.sort((a, b) => a.avgLatency - b.avgLatency);
        break;
      case 'errorRate':
        sorted.sort((a, b) => a.errorRate - b.errorRate);
        break;
    }
    return sorted;
  }, [data, sortBy]);

  // Top 5 for bar chart
  const chartData = sortedData.slice(0, 5).map(entry => ({
    name: entry.name,
    score: entry.score,
  }));

  const chartConfig = {
    data: chartData,
    xField: 'score',
    yField: 'name',
    seriesField: 'name',
    legend: false,
    color: (datum: any) => {
      const entry = sortedData.find(e => e.name === datum.name);
      if (entry?.badge === 'gold') return '#FFD700';
      if (entry?.badge === 'silver') return '#C0C0C0';
      if (entry?.badge === 'bronze') return '#CD7F32';
      return '#1890ff';
    },
    label: {
      position: 'right' as const,
      formatter: (datum: any) => `${datum.score.toFixed(1)}`,
    },
    xAxis: {
      label: {
        formatter: (v: string) => `${v} pts`,
      },
    },
    height: 200,
  };

  const getBadgeIcon = (badge?: 'gold' | 'silver' | 'bronze') => {
    if (badge === 'gold') return <TrophyOutlined style={{ color: '#FFD700', fontSize: 18 }} />;
    if (badge === 'silver') return <TrophyOutlined style={{ color: '#C0C0C0', fontSize: 18 }} />;
    if (badge === 'bronze') return <TrophyOutlined style={{ color: '#CD7F32', fontSize: 18 }} />;
    return null;
  };

  const getScoreColor = (score: number) => {
    if (score >= 80) return '#52c41a';
    if (score >= 60) return '#faad14';
    return '#ff4d4f';
  };

  const columns = [
    {
      title: 'Rank',
      dataIndex: 'rank',
      key: 'rank',
      width: 80,
      render: (rank: number, record: BenchmarkEntry) => (
        <div style={{ display: 'flex', alignItems: 'center', gap: 8 }}>
          {getBadgeIcon(record.badge)}
          <UIText weight="semibold">#{rank}</UIText>
        </div>
      ),
    },
    {
      title: 'Name',
      dataIndex: 'name',
      key: 'name',
      render: (name: string) => <UIText weight="semibold">{name}</UIText>,
    },
    {
      title: 'Score',
      dataIndex: 'score',
      key: 'score',
      width: 120,
      render: (score: number) => (
        <div>
          <Progress
            percent={score}
            size="small"
            strokeColor={getScoreColor(score)}
            format={(percent) => `${percent?.toFixed(0)}`}
          />
        </div>
      ),
      sorter: (a: BenchmarkEntry, b: BenchmarkEntry) => a.score - b.score,
    },
    {
      title: 'Requests',
      dataIndex: 'requests',
      key: 'requests',
      render: (requests: number) => (
        <Tooltip title="Total requests">
          <Space>
            <ThunderboltOutlined style={{ color: '#1890ff' }} />
            <UIText>{requests.toLocaleString()}</UIText>
          </Space>
        </Tooltip>
      ),
      sorter: (a: BenchmarkEntry, b: BenchmarkEntry) => a.requests - b.requests,
    },
    {
      title: 'Avg Latency',
      dataIndex: 'avgLatency',
      key: 'avgLatency',
      render: (latency: number) => {
        const color = latency < 200 ? '#52c41a' : latency < 500 ? '#faad14' : '#ff4d4f';
        return (
          <Tooltip title="Average response time">
            <Space>
              <ClockCircleOutlined style={{ color }} />
              <UIText style={{ color }}>{latency.toFixed(0)}ms</UIText>
            </Space>
          </Tooltip>
        );
      },
      sorter: (a: BenchmarkEntry, b: BenchmarkEntry) => a.avgLatency - b.avgLatency,
    },
    {
      title: 'Error Rate',
      dataIndex: 'errorRate',
      key: 'errorRate',
      render: (errorRate: number) => {
        const color = errorRate < 1 ? '#52c41a' : errorRate < 5 ? '#faad14' : '#ff4d4f';
        return (
          <UITag color={color}>
            {errorRate.toFixed(2)}%
          </UITag>
        );
      },
      sorter: (a: BenchmarkEntry, b: BenchmarkEntry) => a.errorRate - b.errorRate,
    },
  ];

  return (
    <UICard
      title={
        <div style={{ display: 'flex', alignItems: 'center', gap: '8px' }}>
          <HolderOutlined className="drag-handle" style={{ cursor: 'grab', color: '#999' }} />
          <BarChartOutlined />
          <span>Comparative Benchmarks</span>
        </div>
      }
      extra={
        <Space>
          <Segmented
            value={category}
            onChange={(value) => setCategory(value as BenchmarkCategory)}
            options={[
              { label: 'Plugins', value: 'plugins' },
              { label: 'Adapters', value: 'adapters' },
            ]}
          />
          <Segmented
            value={sortBy}
            onChange={(value) => setSortBy(value as SortBy)}
            options={[
              { label: 'Score', value: 'score' },
              { label: 'Requests', value: 'requests' },
              { label: 'Latency', value: 'latency' },
              { label: 'Errors', value: 'errorRate' },
            ]}
          />
        </Space>
      }
      style={{ height: '100%' }}
      bodyStyle={{ padding: '16px', maxHeight: 'calc(100% - 57px)', overflowY: 'auto' }}
    >
      {/* Top Performers Chart */}
      <div style={{ marginBottom: 16 }}>
        <UITitle level={5}>
          <FireOutlined style={{ color: '#ff4d4f' }} /> Top 5 Performers
        </UITitle>
        {chartData.length > 0 ? (
          <KBBarChart {...chartConfig} />
        ) : (
          <div style={{ textAlign: 'center', padding: 40, color: '#999' }}>
            No data available
          </div>
        )}
      </div>

      {/* Benchmark Table */}
      <Table
        dataSource={sortedData}
        columns={columns}
        pagination={{ pageSize: 10 }}
        size="small"
        rowKey="name"
        scroll={{ x: 800 }}
      />

      {/* Scoring Methodology */}
      <div style={{ marginTop: 16, padding: 12, background: '#f0f5ff', borderRadius: 8 }}>
        <UIText weight="semibold">Scoring Methodology:</UIText>
        <div style={{ marginTop: 8, fontSize: 12, color: '#666' }}>
          {category === 'plugins' ? (
            <>
              • <b>Latency (40%)</b>: Lower is better (0ms=100pts, 1000ms=0pts)
              <br />
              • <b>Error Rate (40%)</b>: Lower is better (0%=100pts, 10%+=0pts)
              <br />
              • <b>Throughput (20%)</b>: Higher is better (1000req=100pts)
            </>
          ) : (
            <>
              • <b>Latency (60%)</b>: Lower is better (0ms=100pts, 5000ms=0pts)
              <br />
              • <b>Throughput (40%)</b>: Higher is better (500req=100pts)
            </>
          )}
        </div>
      </div>
    </UICard>
  );
}
